{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet is a lexical database of the English language that groups words into sets of synonyms called synsets, and provides definitions and usage examples for each synset. It also includes relations between words such as hyponymy/hypernymy (subordinate/superordinate) and meronymy/holonymy (part/whole), as well as cross-references to other synsets. WordNet is widely used in natural language processing and computational linguistics applications, and has been the basis for the development of many other language resources and tools."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.book import text4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_noun = \"hair\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Synsets for the noun "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hair.n.01'), Synset('hair's-breadth.n.01'), Synset('hair.n.03'), Synset('hair.n.04'), Synset('haircloth.n.01'), Synset('hair.n.06')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets(selected_noun, pos=wn.NOUN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_noun_synset = wn.synsets(selected_noun)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a covering for the body (or parts of it) consisting of a dense growth of threadlike structures (as on the human head); helps to prevent heat loss'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_noun_synset.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he combed his hair',\n",
       " 'each hair consists of layers of dead keratinized cells']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_noun_synset.examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('hair.n.01.hair')]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_noun_synset.lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing up the WordNet hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('hair.n.01')\n",
      "Synset('body_covering.n.01')\n",
      "Synset('covering.n.01')\n",
      "Synset('natural_object.n.01')\n",
      "Synset('whole.n.02')\n",
      "Synset('object.n.01')\n",
      "Synset('physical_entity.n.01')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "curr = selected_noun_synset\n",
    "while curr:\n",
    "    print(curr)\n",
    "    if not curr.hypernyms():\n",
    "        break\n",
    "    curr = curr.hypernyms()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet nouns if is an object converges to physical_entity or if it is an idea converges abstraction. Then they converge into entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing: hypernyms, hyponyms, meronyms, holonyms, antonym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypernyms: [Synset('body_covering.n.01')] \n",
      "\n",
      "hyponyms: [Synset('beard.n.04'), Synset('body_hair.n.01'), Synset('coat.n.03'), Synset('cowlick.n.01'), Synset('down.n.05'), Synset('eyebrow.n.01'), Synset('eyelash.n.01'), Synset('facial_hair.n.01'), Synset('forelock.n.02'), Synset('guard_hair.n.01'), Synset('hairdo.n.01'), Synset('lock.n.02'), Synset('mane.n.01'), Synset('mane.n.02'), Synset('pubic_hair.n.01')] \n",
      "\n",
      "meronym: [Synset('hairline.n.02'), Synset('part.n.10')] \n",
      "\n",
      "holonyms: [Synset('integumentary_system.n.01')] \n",
      "\n",
      "antonym: [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"hypernyms:\", selected_noun_synset.hypernyms(), \"\\n\")\n",
    "print(\"hyponyms:\", selected_noun_synset.hyponyms(), \"\\n\")\n",
    "print(\"meronym:\", selected_noun_synset.part_meronyms(), \"\\n\")\n",
    "print(\"holonyms:\", selected_noun_synset.part_holonyms(), \"\\n\")\n",
    "\n",
    "antonyms = []\n",
    "for synset in wn.synsets(selected_noun):\n",
    "    for word in synset.lemmas():\n",
    "        for antonym in word.antonyms():\n",
    "            antonyms.append(antonym.name())\n",
    "print(\"antonym:\", antonyms, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_verb = \"run\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Synsets for the verb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('run.v.01'), Synset('scat.v.01'), Synset('run.v.03'), Synset('operate.v.01'), Synset('run.v.05'), Synset('run.v.06'), Synset('function.v.01'), Synset('range.v.01'), Synset('campaign.v.01'), Synset('play.v.18'), Synset('run.v.11'), Synset('tend.v.01'), Synset('run.v.13'), Synset('run.v.14'), Synset('run.v.15'), Synset('run.v.16'), Synset('prevail.v.03'), Synset('run.v.18'), Synset('run.v.19'), Synset('carry.v.15'), Synset('run.v.21'), Synset('guide.v.05'), Synset('run.v.23'), Synset('run.v.24'), Synset('run.v.25'), Synset('run.v.26'), Synset('run.v.27'), Synset('run.v.28'), Synset('run.v.29'), Synset('run.v.30'), Synset('run.v.31'), Synset('run.v.32'), Synset('run.v.33'), Synset('run.v.34'), Synset('ply.v.03'), Synset('hunt.v.01'), Synset('race.v.02'), Synset('move.v.13'), Synset('melt.v.01'), Synset('ladder.v.01'), Synset('run.v.41')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets(selected_verb, pos=wn.VERB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_verb_synset = wn.synsets(selected_verb)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a score in baseball made by a runner touching all four bases safely'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_verb_synset.definition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the Yankees scored 3 runs in the bottom of the 9th',\n",
       " 'their first tally came in the 3rd inning']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_verb_synset.examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synset lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('run.n.01.run'), Lemma('run.n.01.tally')]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_verb_synset.lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing up the WordNet hierarchy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('run.n.01')\n",
      "Synset('score.n.10')\n",
      "Synset('success.n.02')\n",
      "Synset('attainment.n.01')\n",
      "Synset('accomplishment.n.01')\n",
      "Synset('action.n.01')\n",
      "Synset('act.n.02')\n",
      "Synset('event.n.01')\n",
      "Synset('psychological_feature.n.01')\n",
      "Synset('abstraction.n.06')\n",
      "Synset('entity.n.01')\n"
     ]
    }
   ],
   "source": [
    "curr = selected_verb_synset\n",
    "while curr:\n",
    "    print(curr)\n",
    "    if not curr.hypernyms():\n",
    "        break\n",
    "    curr = curr.hypernyms()[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet verb if is an physical activity converges to entity or if it is an idea converges make."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing: hypernyms, hyponyms, meronyms, holonyms, antonym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypernyms: [Synset('score.n.10')] \n",
      "\n",
      "hyponyms: [Synset('earned_run.n.01'), Synset('run_batted_in.n.01'), Synset('unearned_run.n.01')] \n",
      "\n",
      "meronym: [] \n",
      "\n",
      "holonyms: [] \n",
      "\n",
      "antonym: ['malfunction', 'idle'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"hypernyms:\", selected_verb_synset.hypernyms(), \"\\n\")\n",
    "print(\"hyponyms:\", selected_verb_synset.hyponyms(), \"\\n\")\n",
    "print(\"meronym:\", selected_verb_synset.part_meronyms(), \"\\n\")\n",
    "print(\"holonyms:\", selected_verb_synset.part_holonyms(), \"\\n\")\n",
    "\n",
    "antonyms = []\n",
    "for synset in wn.synsets(selected_verb):\n",
    "    for word in synset.lemmas():\n",
    "        for antonym in word.antonyms():\n",
    "            antonyms.append(antonym.name())\n",
    "print(\"antonym:\", antonyms, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"patient\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word as Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy(word, wn.NOUN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word as Adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient\n"
     ]
    }
   ],
   "source": [
    "print(wn.morphy(word, wn.ADJ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wu-Palmer similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('teacher.n.01'), Synset('teacher.n.02')]\n",
      "[Synset('student.n.01'), Synset('scholar.n.01')]\n"
     ]
    }
   ],
   "source": [
    "print(wn.synsets(\"teacher\"))\n",
    "print(wn.synsets(\"student\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_synset = wn.synset('teacher.n.01')\n",
    "student_synset = wn.synset('student.n.01')\n",
    "teacher_synset.path_similarity(student_synset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Wu-Palmer similarity metric is a measure of semantic relatedness between words that takes into account their distance in a semantic hierarchy.\n",
    "Even though the words should be closely related Wu-Palmer similarity metric gives less score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesk algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('ring.n.01') a characteristic sound\n",
      "Synset('ring.n.02') a toroidal shape\n",
      "Synset('hoop.n.02') a rigid circular band of metal or wood or other material used for holding or fastening or hanging or pulling\n",
      "Synset('closed_chain.n.01') (chemistry) a chain of atoms in a molecule that forms a closed loop\n",
      "Synset('gang.n.01') an association of criminals\n",
      "Synset('ring.n.06') the sound of a bell ringing; ; ; --E. A. Poe\n",
      "Synset('ring.n.07') a platform usually marked off by ropes in which contestants box or wrestle\n",
      "Synset('ring.n.08') jewelry consisting of a circlet of precious metal (often set with jewels) worn on the finger\n",
      "Synset('band.n.12') a strip of material attached to the leg of a bird to identify it (as in studies of bird migration)\n",
      "Synset('ring.v.01') sound loudly and sonorously\n",
      "Synset('resound.v.01') ring or echo with sound\n",
      "Synset('ring.v.03') make (bells) ring, often for the purposes of musical edification\n",
      "Synset('call.v.03') get or try to get into communication (with someone) by telephone\n",
      "Synset('surround.v.01') extend on all sides of simultaneously; encircle\n",
      "Synset('ring.v.06') attach a ring to the foot of, in order to identify\n"
     ]
    }
   ],
   "source": [
    "lesk_word = \"ring\"\n",
    "for ss in wn.synsets(lesk_word):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('ring.n.08')\n",
      "Synset('ring.v.06')\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'gave', 'her', 'a', 'ring', '.']\n",
    "print(lesk(sent, 'ring', 'n'))\n",
    "print(lesk(sent, 'ring'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lesk algorithm could be applied to disambiguate the meaning of words in sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SentiWordNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SentiWordNet is a lexical resource that assigns sentiment scores to words in a natural language text. It is based on WordNet, a large lexical database of English words, and provides a way to determine the positivity, negativity, and neutrality of words based on their meanings. \n",
    "* SentiWordNet can be used in NLP applications such as sentiment analysis, opinion mining, and text classification, where the goal is to identify the sentiment of text data. \n",
    "* It can also be used in machine learning to enhance the accuracy of the models that rely on sentiment analysis for decision making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<repose.n.03: PosScore=0.625 NegScore=0.0>\n",
      "Positive score =  0.625\n",
      "Negative score =  0.0\n",
      "Objective score =  0.375\n",
      "\n",
      "<peace.n.03: PosScore=0.125 NegScore=0.5>\n",
      "Positive score =  0.125\n",
      "Negative score =  0.5\n",
      "Objective score =  0.375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emotionally_charged_word = \"serenity\"\n",
    "serenity_senti_synsets = swn.senti_synsets(emotionally_charged_word)\n",
    "\n",
    "for senti_synset in serenity_senti_synsets:\n",
    "  print(senti_synset)\n",
    "  print(\"Positive score = \", senti_synset.pos_score())\n",
    "  print(\"Negative score = \", senti_synset.neg_score())\n",
    "  print(\"Objective score = \", senti_synset.obj_score())\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The       No score found\n",
      "traffic   Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "on        Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "the       No score found\n",
      "way       Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "to        No score found\n",
      "work      Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "was       Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "terrible  Positive = 0.0    Negative = 0.625  Objective = 0.375\n",
      ",         No score found\n",
      "but       Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "the       No score found\n",
      "coffee    Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "from      No score found\n",
      "my        No score found\n",
      "favorite  Positive = 0.25   Negative = 0.0    Objective = 0.75\n",
      "shop      Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "helped    Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "brighten  Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      "my        No score found\n",
      "day       Positive = 0.0    Negative = 0.0    Objective = 1.0\n",
      ".         No score found\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The traffic on the way to work was terrible, but the coffee from my favorite shop helped brighten my day.\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "for token in tokens:\n",
    "    senti_synsets = list(swn.senti_synsets(token))\n",
    "    if senti_synsets:\n",
    "        senti_synset = senti_synsets[0]\n",
    "        pos_score = senti_synset.pos_score()\n",
    "        neg_score = senti_synset.neg_score()\n",
    "        obj_score = senti_synset.obj_score()\n",
    "        print(f\"{token:<9} Positive = {pos_score:<6} Negative = {neg_score:<6} Objective = {obj_score}\")\n",
    "    else:\n",
    "        print(f\"{token:<9} No score found\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that the positive score for \"favorite\" is moderate, while the negative score for \"terrible\" is relatively high. This is consistent with our intuitive understanding of the sentence as being somewhat mixed or neutral in overall sentiment, but leaning slightly negative due to the negative sentiment associated with the traffic.\n",
    "\n",
    "Knowing the sentiment scores for words in a sentence can be very useful in many NLP applications, such as sentiment analysis, opinion mining, and text classification. By analyzing the sentiment of words and phrases in a text, we can gain insight into the attitudes and opinions expressed in that text, and use that information to make predictions or recommendations about how to respond or act on that text. However, it's important to note that sentiment analysis is still a challenging problem, and the accuracy of sentiment scores can be affected by many factors, such as context, sarcasm, and the nuances of language."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collocations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In linguistics, a collocation is a sequence of words or terms that co-occur more often than would be expected by chance. \n",
    "* Collocations can be made up of two or more words and are often idiomatic, meaning that their meaning cannot be inferred from the meanings of their individual words. \n",
    "* Collocations are important in language learning and natural language processing, as they can provide insights into how words are used together in different contexts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations of nltk text4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "text4.collocations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability(God bless) =  0.0016957605985037406\n",
      "probability(God) =  0.011172069825436408\n",
      "probability(bless) =  0.0085785536159601\n",
      "pmi =  4.145157780720282\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(text4.tokens)\n",
    "vocab = len(set(text4))\n",
    "\n",
    "gb = text.count('God bless')/vocab\n",
    "print(\"probability(God bless) = \", gb)\n",
    "\n",
    "g = text.count('God')/vocab\n",
    "print(\"probability(God) = \", g)\n",
    "\n",
    "b = text.count('bless')/vocab\n",
    "print('probability(bless) = ', b)\n",
    "\n",
    "pmi = math.log2(gb / (g * b))\n",
    "print('pmi = ', pmi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutual information score for the \"God bless\" collocation is 4.15, which is a high score. This suggests that \"God\" and \"bless\" are highly associated with each other and are very likely to form a collocation. As \"God bless\" is a common and frequently used expression in English, particularly in religious and patriotic contexts. The high mutual information score suggests that the \"God bless\" collocation could be a useful feature in NLP applications that deal with sentiment analysis, topic modeling, or other tasks that involve identifying and analyzing collocations in text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WordNet-OeouFkxG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25ca5efa60d844c707868e6ef1a85951ca3e23474377d0ba8ea654117bb6a8a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
